{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 사용한 코드"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from PIL import Image\r\n",
    "import os, glob\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "\r\n",
    "\r\n",
    "def resize_images(img_path): #하위폴더 가위바위보 리사이즈로 변경\r\n",
    "    images=glob.glob(img_path + \"/scissor/*.jpg\")  \r\n",
    "    \r\n",
    "    target_size=(28,28)\r\n",
    "    for img in images:\r\n",
    "        old_img=Image.open(img)\r\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\r\n",
    "        new_img.save(img, \"JPEG\")\r\n",
    "    \r\n",
    "    images=glob.glob(img_path + \"/paper/*.jpg\")  \r\n",
    "    \r\n",
    "    for img in images:\r\n",
    "        old_img=Image.open(img)\r\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\r\n",
    "        new_img.save(img, \"JPEG\")\r\n",
    "    \r\n",
    "    images=glob.glob(img_path + \"/rock/*.jpg\")  \r\n",
    "    \r\n",
    "    for img in images:\r\n",
    "        old_img=Image.open(img)\r\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\r\n",
    "        new_img.save(img, \"JPEG\")\r\n",
    "    \r\n",
    "\r\n",
    "def load_data(img_path, number_of_data=900):  # 가위바위보 이미지 개수 총합에 주의하세요.\r\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\r\n",
    "    img_size=28\r\n",
    "    color=3\r\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\r\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\r\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\r\n",
    "\r\n",
    "    idx=0\r\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\r\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\r\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\r\n",
    "        labels[idx]=0   # 가위 : 0\r\n",
    "        idx=idx+1\r\n",
    "\r\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\r\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\r\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\r\n",
    "        labels[idx]=1   # 바위 : 1\r\n",
    "        idx=idx+1  \r\n",
    "    \r\n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\r\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\r\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\r\n",
    "        labels[idx]=2   # 보 : 2\r\n",
    "        idx=idx+1\r\n",
    "        \r\n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\r\n",
    "    return imgs, labels\r\n",
    "\r\n",
    "# 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\r\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\r\n",
    "resize_images(image_dir_path) #학습용 데이터 리사이즈\r\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\r\n",
    "resize_images(image_dir_path) #시험용 데이터 리사이즈\r\n",
    "\r\n",
    "print(\"가위바위보 이미지 resize 완료!\")\r\n",
    "\r\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\" #원본 입력\r\n",
    "(x_train, y_train)=load_data(image_dir_path)\r\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\r\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3)\r\n",
    "\r\n",
    "imagetest_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\" # 테스트값 입력\r\n",
    "(x_test, y_test)=load_data(imagetest_dir_path)\r\n",
    "x_test_norm = x_test/255.0  \r\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)\r\n",
    "\r\n",
    "n_channel_1=16 #하이퍼파라메타\r\n",
    "n_channel_2=64\r\n",
    "n_dense=32\r\n",
    "n_train_epoch=10\r\n",
    "\r\n",
    "model=keras.models.Sequential() #학습네트웍 구축\r\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\r\n",
    "model.add(keras.layers.MaxPool2D(2,2))\r\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\r\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\r\n",
    "model.add(keras.layers.Flatten())\r\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\r\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\r\n",
    "\r\n",
    "\r\n",
    "model.summary()\r\n",
    "\r\n",
    "model.compile(optimizer='adam',\r\n",
    "             loss='sparse_categorical_crossentropy',\r\n",
    "             metrics=['accuracy']) #컴파일\r\n",
    "\r\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)\r\n",
    "\r\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)#시험셋과 비교\r\n",
    "print(\"test_loss: {} \".format(test_loss))\r\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "가위바위보 이미지 resize 완료!\n",
      "학습데이터(x_train)의 이미지 개수는 625 입니다.\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                51232     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 61,059\n",
      "Trainable params: 61,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 6s 78ms/step - loss: 1.0760 - accuracy: 0.5775\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.9083 - accuracy: 0.5803\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.7122 - accuracy: 0.6202\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.6533\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.7411\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7507\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.8539\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.9235\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3274 - accuracy: 0.9297\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9729\n",
      "29/29 - 0s - loss: 0.8409 - accuracy: 0.7778\n",
      "test_loss: 0.8409276008605957 \n",
      "test_accuracy: 0.7777777910232544\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 고찰"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "막연히 되겠거니 하고 한꺼번에 모아서 붙여서 작업하였더니 어디서 터진건지 찾을수가 없었다   \n",
    "나눠서 작업하고 곳곳에 완료 메시지를 프린팅 해줌으로써 빠르고 안정적인 컴퓨팅이 가능할꺼 같다"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 회고"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "비록 인식률이 나쁘지만 주물러서 돌아가는 걸 보니 기쁩니다.   \n",
    "또한 프로그램을 짜는 것도 짜는 거지만 원본데이터의 중요성이 엄청 크다는걸 느꼈습니다."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5ca766358246449af30efc9a143909eb4260c2a8a600fb7f3dd1a3691834c47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}