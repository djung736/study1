{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\r\n",
    "import os, glob\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "\r\n",
    "\r\n",
    "def resize_images(img_path): #하위폴더 가위바위보 리사이즈로 변경\r\n",
    "    images=glob.glob(img_path + \"/scissor/*.jpg\")  \r\n",
    "    \r\n",
    "    target_size=(28,28)\r\n",
    "    for img in images:\r\n",
    "        old_img=Image.open(img)\r\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\r\n",
    "        new_img.save(img, \"JPEG\")\r\n",
    "    \r\n",
    "    images=glob.glob(img_path + \"/paper/*.jpg\")  \r\n",
    "    \r\n",
    "    for img in images:\r\n",
    "        old_img=Image.open(img)\r\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\r\n",
    "        new_img.save(img, \"JPEG\")\r\n",
    "    \r\n",
    "    images=glob.glob(img_path + \"/rock/*.jpg\")  \r\n",
    "    \r\n",
    "    for img in images:\r\n",
    "        old_img=Image.open(img)\r\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\r\n",
    "        new_img.save(img, \"JPEG\")\r\n",
    "    \r\n",
    "\r\n",
    "def load_data(img_path, number_of_data=900):  # 가위바위보 이미지 개수 총합에 주의하세요.\r\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\r\n",
    "    img_size=28\r\n",
    "    color=3\r\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\r\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\r\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\r\n",
    "\r\n",
    "    idx=0\r\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\r\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\r\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\r\n",
    "        labels[idx]=0   # 가위 : 0\r\n",
    "        idx=idx+1\r\n",
    "\r\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\r\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\r\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\r\n",
    "        labels[idx]=1   # 바위 : 1\r\n",
    "        idx=idx+1  \r\n",
    "    \r\n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\r\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\r\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\r\n",
    "        labels[idx]=2   # 보 : 2\r\n",
    "        idx=idx+1\r\n",
    "        \r\n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\r\n",
    "    return imgs, labels\r\n",
    "\r\n",
    "# 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\r\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\r\n",
    "resize_images(image_dir_path) #학습용 데이터 리사이즈\r\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\r\n",
    "resize_images(image_dir_path) #시험용 데이터 리사이즈\r\n",
    "\r\n",
    "print(\"가위바위보 이미지 resize 완료!\")\r\n",
    "\r\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\" #원본 입력\r\n",
    "(x_train, y_train)=load_data(image_dir_path)\r\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\r\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3)\r\n",
    "\r\n",
    "imagetest_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\" # 테스트값 입력\r\n",
    "(x_test, y_test)=load_data(imagetest_dir_path)\r\n",
    "x_test_norm = x_test/255.0  \r\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)\r\n",
    "\r\n",
    "n_channel_1=16 #하이퍼파라메타\r\n",
    "n_channel_2=64\r\n",
    "n_dense=32\r\n",
    "n_train_epoch=10\r\n",
    "\r\n",
    "model=keras.models.Sequential() #학습네트웍 구축\r\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\r\n",
    "model.add(keras.layers.MaxPool2D(2,2))\r\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\r\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\r\n",
    "model.add(keras.layers.Flatten())\r\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\r\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\r\n",
    "\r\n",
    "\r\n",
    "model.summary()\r\n",
    "\r\n",
    "model.compile(optimizer='adam',\r\n",
    "             loss='sparse_categorical_crossentropy',\r\n",
    "             metrics=['accuracy']) #컴파일\r\n",
    "\r\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)\r\n",
    "\r\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)#시험셋과 비교\r\n",
    "print(\"test_loss: {} \".format(test_loss))\r\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가위바위보 이미지 resize 완료!\r\n",
    "학습데이터(x_train)의 이미지 개수는 625 입니다.\r\n",
    "학습데이터(x_train)의 이미지 개수는 300 입니다.\r\n",
    "Model: \"sequential_24\"\r\n",
    "_________________________________________________________________\r\n",
    "Layer (type)                 Output Shape              Param #   \r\n",
    "=================================================================\r\n",
    "conv2d_48 (Conv2D)           (None, 26, 26, 16)        448       \r\n",
    "_________________________________________________________________\r\n",
    "max_pooling2d_48 (MaxPooling (None, 13, 13, 16)        0         \r\n",
    "_________________________________________________________________\r\n",
    "conv2d_49 (Conv2D)           (None, 11, 11, 64)        9280      \r\n",
    "_________________________________________________________________\r\n",
    "max_pooling2d_49 (MaxPooling (None, 5, 5, 64)          0         \r\n",
    "_________________________________________________________________\r\n",
    "flatten_24 (Flatten)         (None, 1600)              0         \r\n",
    "_________________________________________________________________\r\n",
    "dense_48 (Dense)             (None, 32)                51232     \r\n",
    "_________________________________________________________________\r\n",
    "dense_49 (Dense)             (None, 3)                 99        \r\n",
    "=================================================================\r\n",
    "Total params: 61,059\r\n",
    "Trainable params: 61,059\r\n",
    "Non-trainable params: 0\r\n",
    "_________________________________________________________________\r\n",
    "Epoch 1/10\r\n",
    "29/29 [==============================] - 0s 3ms/step - loss: 1.0669 - accuracy: 0.5777\r\n",
    "Epoch 2/10\r\n",
    "29/29 [==============================] - 0s 3ms/step - loss: 0.8061 - accuracy: 0.6351\r\n",
    "Epoch 3/10\r\n",
    "29/29 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.6458\r\n",
    "Epoch 4/10\r\n",
    "29/29 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.7231\r\n",
    "Epoch 5/10\r\n",
    "29/29 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.8272\r\n",
    "Epoch 6/10\r\n",
    "29/29 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8916\r\n",
    "Epoch 7/10\r\n",
    "29/29 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.9385\r\n",
    "Epoch 8/10\r\n",
    "29/29 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.9313\r\n",
    "Epoch 9/10\r\n",
    "29/29 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9760\r\n",
    "Epoch 10/10\r\n",
    "29/29 [==============================] - 0s 3ms/step - loss: 0.0902 - accuracy: 0.9903\r\n",
    "29/29 - 0s - loss: 1.1156 - accuracy: 0.7778\r\n",
    "test_loss: 1.1155623197555542 \r\n",
    "test_accuracy: 0.7777777910232544"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 고찰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "막연히 되겠거니 하고 한꺼번에 모아서 붙여서 작업하였더니 어디서 터진건지 찾을수가 없었다   \r\n",
    "나눠서 작업하고 곳곳에 완료 메시지를 프린팅 해줌으로써 빠르고 안정적인 컴퓨팅이 가능할꺼 같다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비록 인식률이 나쁘지만 주물러서 돌아가는 걸 보니 기쁩니다.   \r\n",
    "또한 프로그램을 짜는 것도 짜는 거지만 원본데이터의 중요성이 엄청 크다는걸 느꼈습니다."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5ca766358246449af30efc9a143909eb4260c2a8a600fb7f3dd1a3691834c47"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
