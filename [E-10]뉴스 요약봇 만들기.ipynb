{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dental-flour",
   "metadata": {},
   "source": [
    "Step 1. 데이터 수집하기\n",
    "\n",
    "데이터는 아래 링크에 있는 뉴스 기사 데이터(news_summary_more.csv)를 사용하세요.\n",
    "\n",
    "이 데이터는 기사의 본문에 해당되는 text와 headlines 두 가지 열로 구성되어져 있습니다.\n",
    "\n",
    "추상적 요약을 하는 경우에는 text를 본문, headlines를 이미 요약된 데이터로 삼아서 모델을 학습할 수 있어요. 추출적 요약을 하는 경우에는 오직 text열만을 사용하세요.   \n",
    "Step 2. 데이터 전처리하기 (추상적 요약)\n",
    "\n",
    "실습에서 사용된 전처리를 참고하여 각자 필요하다고 생각하는 전처리를 추가 사용하여 텍스트를 정규화 또는 정제해 보세요. 만약, 불용어 제거를 선택한다면 상대적으로 길이가 짧은 요약 데이터에 대해서도 불용어를 제거하는 것이 좋을지 고민해 보세요.   \n",
    "Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)\n",
    "\n",
    "일반적인 seq2seq보다는 어텐션 메커니즘을 사용한 seq2seq를 사용하는 것이 더 나은 성능을 얻을 수 있어요. 실습 내용을 참고하여 어텐션 메커니즘을 사용한 seq2seq를 설계해 보세요.   \n",
    "Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)\n",
    "\n",
    "원래의 요약문(headlines 열)과 학습을 통해 얻은 추상적 요약의 결과를 비교해 보세요.    \n",
    "Step 5. Summa을 이용해서 추출적 요약해보기\n",
    "\n",
    "추상적 요약은 추출적 요약과는 달리 문장의 표현력을 다양하게 가져갈 수 있지만, 추출적 요약에 비해서 난이도가 높아요. 반대로 말하면 추출적 요약은 추상적 요약에 비해 난이도가 낮고 기존 문장에서 문장을 꺼내오는 것이므로 잘못된 요약이 나올 가능성이 낮아요.\n",
    "\n",
    "Summa의 summarize를 사용하여 추출적 요약을 해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fleet-friday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "direct-marathon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55515</th>\n",
       "      <td>43rd Annual Cake Show begins in Bengaluru</td>\n",
       "      <td>Dubbed as India's biggest annual cake show, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62331</th>\n",
       "      <td>Aishwarya Rai donates free meals to 1,000 kids...</td>\n",
       "      <td>Actress Aishwarya Rai Bachchan donated free me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57196</th>\n",
       "      <td>Congress is habitual of blaming EVMs: Union mi...</td>\n",
       "      <td>Union minister Jitendra Singh on Saturday said...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71098</th>\n",
       "      <td>GrubHub is not a food delivery company, says C...</td>\n",
       "      <td>Online food ordering platform GrubHub's COO St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29603</th>\n",
       "      <td>Smith, Sammy accuse Aus IPL coaches of favouri...</td>\n",
       "      <td>Former South African captain Graeme Smith and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66914</th>\n",
       "      <td>What an honour: Hardik Pandya on poster with A...</td>\n",
       "      <td>Indian all-rounder Hardik Pandya took to Twitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15639</th>\n",
       "      <td>What is Sabarimala Temple case that SC will de...</td>\n",
       "      <td>A five-judge Supreme Court bench will today de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38138</th>\n",
       "      <td>Men with fake pregnancy bellies walk the ramp ...</td>\n",
       "      <td>Chinese designer Xander Zhou made male models ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80594</th>\n",
       "      <td>400 kg of ganja worth Ã¢ÂÂ¹40 lakh seized in ...</td>\n",
       "      <td>The Andhra Pradesh Police on Wednesday arreste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39884</th>\n",
       "      <td>SpaceX launches communications satellite on Fa...</td>\n",
       "      <td>Elon Musk-led space exploration startup SpaceX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "55515          43rd Annual Cake Show begins in Bengaluru   \n",
       "62331  Aishwarya Rai donates free meals to 1,000 kids...   \n",
       "57196  Congress is habitual of blaming EVMs: Union mi...   \n",
       "71098  GrubHub is not a food delivery company, says C...   \n",
       "29603  Smith, Sammy accuse Aus IPL coaches of favouri...   \n",
       "66914  What an honour: Hardik Pandya on poster with A...   \n",
       "15639  What is Sabarimala Temple case that SC will de...   \n",
       "38138  Men with fake pregnancy bellies walk the ramp ...   \n",
       "80594  400 kg of ganja worth Ã¢ÂÂ¹40 lakh seized in ...   \n",
       "39884  SpaceX launches communications satellite on Fa...   \n",
       "\n",
       "                                                    text  \n",
       "55515  Dubbed as India's biggest annual cake show, th...  \n",
       "62331  Actress Aishwarya Rai Bachchan donated free me...  \n",
       "57196  Union minister Jitendra Singh on Saturday said...  \n",
       "71098  Online food ordering platform GrubHub's COO St...  \n",
       "29603  Former South African captain Graeme Smith and ...  \n",
       "66914  Indian all-rounder Hardik Pandya took to Twitt...  \n",
       "15639  A five-judge Supreme Court bench will today de...  \n",
       "38138  Chinese designer Xander Zhou made male models ...  \n",
       "80594  The Andhra Pradesh Police on Wednesday arreste...  \n",
       "39884  Elon Musk-led space exploration startup SpaceX...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", \n",
    "                           filename=\"news_summary_more.csv\")\n",
    "\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nutritional-lover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fourth-shift",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-slovenia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "assisted-proxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nuclear-collect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "young-garbage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "turkish-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (headlines)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rotary-nightlife",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adult-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425.53704166412354  seconds\n",
      "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers'\n",
      " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit'\n",
      " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history'\n",
      " ...\n",
      " 'according reports new version science fiction film matrix development michael jordan reportedly play lead role film screenwriter zak penn talks write script film reports added actor keanu reeves starred original film followed two sequels'\n",
      " 'new music video shows rapper snoop dogg aiming toy gun clown character parodying us president donald trump video also shows tv airing news conference headline ronald klump wants deport doggs airing live clown house video remixed version song lavender'\n",
      " 'madhesi morcha alliance seven political parties withdrawn support pm pushpa kamal dahal led nepal government failed meet seven day ultimatum fulfil demands including endorsement revised constitution amendment bill morcha seats parliament despite withdrawal support immediate threat government']\n",
      "12.638416767120361  seconds\n",
      "['upgrad learner switches to career in ml al with salary hike'\n",
      " 'delhi techie wins free food from swiggy for one year on cred'\n",
      " 'new zealand end rohit sharma led india match winning streak' ...\n",
      " 'the matrix film to get reboot reports'\n",
      " 'snoop dogg aims gun at clown dressed as trump in new video'\n",
      " 'madhesi morcha withdraws support to nepalese government']\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp   # 멀티 프로세싱으로 전처리 속도를 획기적으로 줄여봅시다\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import partial  # map을 할 때 함수에 여러 인자를 넣어줄 수 있도록 합니다\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# num_cores 만큼 쪼개진 데이터를 전처리하여 반환합니다\n",
    "def appendTexts(sentences, remove_stopwords):\n",
    "    texts = []\n",
    "    for s in sentences:\n",
    "        texts += preprocess_sentence(s, remove_stopwords),\n",
    "    return texts\n",
    "\n",
    "def preprocess_data(data, remove_stopwords=True):\n",
    "    start_time = time.time()\n",
    "    num_cores = mp.cpu_count()  # 컴퓨터의 코어 수를 구합니다\n",
    "\n",
    "    text_data_split = np.array_split(data, num_cores)  # 코어 수만큼 데이터를 배분하여 병렬적으로 처리할 수 있게 합니다\n",
    "    pool = Pool(num_cores)\n",
    "\n",
    "    processed_data = np.concatenate(pool.map(partial(appendTexts, remove_stopwords=remove_stopwords), text_data_split))  \n",
    "    # 각자 작업한 데이터를 하나로 합쳐줍니다\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(time.time() - start_time, \" seconds\")\n",
    "    return processed_data\n",
    "\n",
    "clean_text = preprocess_data(data['text'])  # 클라우드 기준으로 7분 정도 소요 됩니다\n",
    "print(clean_text)\n",
    "\n",
    "clean_headlines = preprocess_data(data['headlines'], remove_stopwords=False) # 클라우드 기준 1분정도 소요됩니다.\n",
    "print(clean_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "awful-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "disabled-dream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "narrative-chassis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "honest-sunday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAf5UlEQVR4nO3df7hdVX3n8feHoGgVBSTmCYSYoFGLViNEwEd0UCoEsAU7FqFVIlJSKihOrU6wjjBU2jC2WG1tNJaUYBFkRCQjUYwpSJ0KJEBK+CFDCKEkhiQSIEFsNOEzf+x1ZXO59+Zk555z7sn9vJ5nP3fv7/61Frnkm7322mvJNhEREU3s1u0CRERE70oSiYiIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjGkkQiIqKxJJGINpH0ZG15WtIvatt/2OB6R0pa3Y6yRjS1e7cLELGrsv3ivnVJq4A/sv2D7pUoYvjlSSSiwyTtJmmWpAckPSrpKkn7lH1zJF1dO/YiSYslvQj4LrBf7Wlmv27VIaJPkkhE530EOBH4L8B+wGPAl8q+jwO/JemDkt4GnA7MsP1z4Fjgp7ZfXJafdr7oEc+W5qyIzjsTONv2agBJ5wP/IekDtp+S9AGqp47NwEf6josYiZJEIjrvFcA1kp6uxbYB44A1tm+RtBJ4OXBVNwoY0ao0Z0V03sPAsbb3qi0vsL0GQNJZwB7AT4FP1s7LkNsx4iSJRHTel4ELJb0CQNJYSSeU9VcDnwXeD3wA+KSkqeW8dcDLJL2080WOGFiSSETnfQFYAHxf0mbgZuAwSbsD/wxcZPvfbd8PfAr4mqQ9bP8EuAJYKenx9M6KkUCZlCoiIprKk0hERDSWJBIREY0liURERGNJIhER0dio+9hw33339aRJk7pdjIiInnLbbbf9zPbY/vFRl0QmTZrE0qVLu12MiIieIumhgeJpzoqIiMaSRCIiorEkkYiIaCxJJCIiGksSiYiIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjG2vbFuqQDgMuo5o02MNf2FyTtA3wDmASsAk6y/ZgkUU3WcxzwFPBB27eXa80APl0u/Vnb80v8EOBS4IXAQuAcZ4KUiOeYNOu6Ifevmn18h0oSu5p2PolsBT5u+yDgcOAsSQcBs4DFtqcAi8s2wLHAlLLMBOYAlKRzHnAYcChwnqS9yzlzgDNq501vY30iIqKftiUR22v7niRsbwbuBfYHTgDml8PmAyeW9ROAy1y5GdhL0njgGGCR7Y22HwMWAdPLvpfYvrk8fVxWu1ZERHRAR96JSJoEvAm4BRhne23Z9QhVcxdUCebh2mmrS2yo+OoB4gPdf6akpZKWbtiwYecqExERv9b2JCLpxcDVwMdsb6rvK08QbX+HYXuu7Wm2p40d+5yRjCMioqG2JhFJz6NKIJfb/lYJrytNUZSf60t8DXBA7fQJJTZUfMIA8YiI6JC2JZHS2+oS4F7bF9d2LQBmlPUZwLW1+KmqHA48UZq9rgeOlrR3eaF+NHB92bdJ0uHlXqfWrhURER3Qzkmp3gp8AFguaVmJfQqYDVwl6XTgIeCksm8hVffeFVRdfE8DsL1R0l8AS8pxF9jeWNY/zDNdfL9bloiI6JC2JRHbPwI0yO6jBjjewFmDXGseMG+A+FLg9TtRzIiI2An5Yj0iIhpLEomIiMaSRCIiorEkkYiIaCxJJCIiGksSiYiIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjGkkQiIqKxJJGIiGgsSSQiIhpLEomIiMaSRCIiorEkkYiIaKyd0+POk7Re0l212DckLSvLqr4ZDyVNkvSL2r4v1845RNJySSskfbFMhYukfSQtknR/+bl3u+oSEREDa+eTyKXA9HrA9vtsT7U9Fbga+FZt9wN9+2yfWYvPAc4AppSl75qzgMW2pwCLy3ZERHRQ25KI7ZuAjQPtK08TJwFXDHUNSeOBl9i+uUyfexlwYtl9AjC/rM+vxSMiokO69U7kbcA62/fXYpMl3SHph5LeVmL7A6trx6wuMYBxtteW9UeAcW0tcUREPMfuXbrvKTz7KWQtMNH2o5IOAb4t6XWtXsy2JXmw/ZJmAjMBJk6c2LDIERHRX8efRCTtDvwe8I2+mO0tth8t67cBDwCvBtYAE2qnTygxgHWluauv2Wv9YPe0Pdf2NNvTxo4dO5zViYgY1brRnPXbwE9s/7qZStJYSWPK+oFUL9BXluaqTZIOL+9RTgWuLactAGaU9Rm1eEREdEg7u/heAfwYeI2k1ZJOL7tO5rkv1N8O3Fm6/H4TONN230v5DwP/CKygekL5bonPBt4l6X6qxDS7XXWJiIiBte2diO1TBol/cIDY1VRdfgc6finw+gHijwJH7VwpIyJiZ+SL9YiIaCxJJCIiGksSiYiIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjGujV2VkTsoEmzrht036rZx3ewJBHPyJNIREQ0liQSERGNJYlERERjSSIREdFYkkhERDSWJBIREY0liURERGNJIhER0ViSSERENNbO6XHnSVov6a5a7HxJayQtK8txtX3nSloh6T5Jx9Ti00tshaRZtfhkSbeU+DckPb9ddYmIiIFtN4lI+n1Je5b1T0v6lqSDW7j2pcD0AeKftz21LAvLdQ+imnv9deWcf5A0RtIY4EvAscBBwCnlWICLyrVeBTwGnN7/RhER0V6tPIn8D9ubJR0B/DZwCTBneyfZvgnY2GI5TgCutL3F9oPACuDQsqywvdL2L4ErgRMkCXgn8M1y/nzgxBbvFRERw6SVJLKt/DwemGv7OmBnmo7OlnRnae7au8T2Bx6uHbO6xAaLvwx43PbWfvEBSZopaamkpRs2bNiJokdERF0rSWSNpK8A7wMWStqjxfMGMgd4JTAVWAv8TcPr7BDbc21Psz1t7NixnbhlRMSo0EoyOAm4HjjG9uPAPsAnmtzM9jrb22w/DXyVqrkKYA1wQO3QCSU2WPxRYC9Ju/eLR0REB203idh+ClgPHFFCW4H7m9xM0vja5nuAvp5bC4CTJe0haTIwBbgVWAJMKT2xnk/18n2BbQM3AO8t588Arm1SpoiIaG67k1JJOg+YBrwG+CfgecA/A2/dznlXAEcC+0paDZwHHClpKmBgFfDHALbvlnQVcA9VkjrL9rZynbOpnoTGAPNs311u8d+BKyV9FriD6oV/RER0UCszG74HeBNwO4Dtn/Z1+R2K7VMGCA/6F73tC4ELB4gvBBYOEF/JM81hERHRBa28E/llaT4ygKQXtbdIERHRK1pJIleV3ll7SToD+AHVS/GIiBjlttucZfuvJb0L2ET1XuQzthe1vWQRETHitfJOhJI0kjgiIuJZBk0ikjZT3oP03wXY9kvaVqqIiOgJgyYR29vtgRUREaNbS81ZZdTeI6ieTH5k+462lioiRoxJs64bcv+q2cd3qCQxErUyFPxnqEbJfRmwL3CppE+3u2ARETHytfIk8ofAG23/J4Ck2cAy4LNtLFdERPSAVr4T+Snwgtr2HmSww4iIoLUnkSeAuyUtonon8i7gVklfBLD90TaWLyIiRrBWksg1ZelzY3uKEhERvaaVL9bnd6IgERHRe1rpnfVuSXdI2ihpk6TNkjZ1onARETGytdKc9bfA7wHLy2i+ERERQGu9sx4G7koCiYiI/lp5EvkksFDSD4EtfUHbFw91kqR5wLuB9bZfX2KfA34H+CXwAHCa7cclTQLuBe4rp99s+8xyziHApcALqSanOse2Je0DfAOYRDVL4km2H2uhPhERMUxaeRK5EHiK6luRPWvL9lwKTO8XWwS83vYbgP8HnFvb94DtqWU5sxafA5xBNe/6lNo1ZwGLbU8BFpftiIjooFaeRPbre5LYEbZvKk8Y9dj3a5s3A+8d6hqSxgMvsX1z2b4MOBH4LnAC1RzuUA3LciPVvOsREdEhrTyJLJR0dBvu/SGqZNBncukF9kNJbyux/YHVtWNWlxjAONtry/ojwLjBbiRppqSlkpZu2LBhmIofERGtJJE/Ab4n6RfD1cVX0p8DW4HLS2gtMNH2m4A/Bb4uqeX5SupzwA+yf67tabanjR07didKHhERda18bDis84pI+iDVC/ej+np82d5CeWlv+zZJDwCvphqja0Lt9Ak8M27XOknjba8tzV7rh7OcERGxfa08iSBpb0mHSnp739LkZpKmU/X2+l3bT9XiYyWNKesHUr1AX1maqzZJOlySgFOBa8tpC4AZZX1GLR4RER2y3ScRSX8EnEP1FLAMOBz4MfDO7Zx3BdWL730lrQbOo+qNtQewqMoJv+7K+3bgAkm/Ap4GzrS9sVzqwzzTxfe7PPMeZTZwlaTTgYeAk1qpcEREDJ9WemedA7yZ6i/8d0h6LfCX2zvJ9ikDhC8Z5NirgasH2bcUeE7vMNuPAkdtrxwREdE+rTRn/WdtQqo9bP8EeE17ixUREb2glSeR1ZL2Ar5N1Qz1GFXzUUREjHKt9M56T1k9X9INwEuB77W1VBER0RNaGQr+lZL26NukGqvqN9pZqIiI6A2tvBO5Gtgm6VXAXOAA4OttLVVERPSEVpLI07a3Au8B/s72J4Dx7S1WRET0glaSyK8knUL1Qd93Sux57StSRET0ilaSyGnAW4ALbT8oaTLwtfYWKyIiekErvbPuAT5a234QuKidhYqIiN7Q0thZERERA0kSiYiIxgZNIpK+Vn6e07niRERELxnqSeQQSfsBHypDwe9TXzpVwIiIGLmGerH+ZWAxcCBwG9XX6n1c4hERMYoN+iRi+4u2fxOYZ/tA25NrSxJIRES01MX3TyS9EXhbCd1k+872FisiInpBKwMwfhS4HHh5WS6X9JF2FywiIka+Vrr4/hFwmO3P2P4M1fS4Z7RycUnzJK2XdFctto+kRZLuLz/3LnFJ+qKkFZLulHRw7ZwZ5fj7Jc2oxQ+RtLyc88UyD3tERHRIK0lEwLba9jae/ZJ9KJcC0/vFZgGLbU+henE/q8SPBaaUZSYwB6qkQzU/+2HAocB5fYmnHHNG7bz+94qIiDZqJYn8E3CLpPMlnQ/czCBzpfdn+yZgY7/wCcD8sj4fOLEWv8yVm4G9JI0HjgEW2d5o+zFgETC97HuJ7ZttG7isdq2IiOiAVl6sXyzpRuCIEjrN9h07cc9xtteW9UeAcWV9f+Dh2nGrS2yo+OoB4s8haSbV0w0TJ07ciaJHjEyTZl3X7SLEKNXKHOvYvh24fbhvbtuSPNzXHeA+c6km1GLatGltv19ExGjRjbGz1pWmKMrP9SW+hmrWxD4TSmyo+IQB4hER0SHdSCILqCa4ovy8thY/tfTSOhx4ojR7XQ8cXYZe2Rs4Gri+7Nsk6fDSK+vU2rUiIqIDhmzOkjQG+IHtdzS5uKQrgCOBfSWtpuplNRu4StLpwEPASeXwhcBxwArgKarJsLC9UdJfAEvKcRfY7ntZ/2GqHmAvBL5bloiI6JAhk4jtbZKelvRS20/s6MVtnzLIrqMGONbAWYNcZx4wb4D4UuD1O1quiIgYHq28WH8SWC5pEfDzvqDtjw5+SkREjAatJJFvlSUidlHpIhxNtfKdyHxJLwQm2r6vA2WKiIge0coAjL8DLAO+V7anSlrQ5nJFREQPaKWL7/lUY1Y9DmB7GZmQKiIiaC2J/GqAnllPt6MwERHRW1p5sX63pD8AxkiaAnwU+Lf2FisiInpBK08iHwFeB2wBrgA2AR9rY5kiIqJHtNI76yngzyVdVG16c/uLFRERvaCV3llvlrQcuJPqo8N/l3RI+4sWEREjXSvvRC4BPmz7XwEkHUE1UdUb2lmwiIgY+Vp5J7KtL4EA2P4RsLV9RYqIiF4x6JOIpIPL6g8lfYXqpbqB9wE3tr9oEREx0g3VnPU3/bbPq61ndsCIiBg8iTSdQyQiIkaP7b5Yl7QX1ayBk+rHZyj4iIho5cX6QqoEshy4rbY0Iuk1kpbVlk2SPibpfElravHjauecK2mFpPskHVOLTy+xFZJmNS1TREQ000oX3xfY/tPhumEZTn4q/Hr63TXANVTT4X7e9l/Xj5d0EHAy1Vfz+wE/kPTqsvtLwLuA1cASSQts3zNcZY2IiKG1kkS+JukM4DtUQ58A1dznw3D/o4AHbD8kabBjTgCutL0FeFDSCqpRhQFW2F4JIOnKcmySSEREh7TSnPVL4HPAj3mmKWvpMN3/ZKquw33OlnSnpHmS9i6x/YGHa8esLrHB4s8haaakpZKWbtiwYZiKHhERrSSRjwOvsj3J9uSy7PR8IpKeD/wu8L9LaA7wSqqmrrU8t4txY7bn2p5me9rYsWOH67IREaNeK81ZK4Cn2nDvY4Hbba8D6PsJIOmrVM1nUL0zOaB23oQSY4h4RER0QCtJ5OfAMkk38Ox3IjvbxfcUak1ZksbbXls23wPcVdYXAF+XdDHVi/UpwK2AgCmSJlMlj5OBP9jJMkVExA5oJYl8uyzDRtKLqHpV/XEt/L8kTaX6Gn5V3z7bd0u6iuqF+VbgLNvbynXOBq4HxgDzbN89nOWMiIihtTKfyPzhvqntnwMv6xf7wBDHXwhcOEB8IdV3LBER0QWtfLH+IAOMlTUcL9cjIqK3tdKcNa22/gLg94F92lOciIjoJdvt4mv70dqyxvbfAse3v2gRETHStdKcdXBtczeqJ5NWnmAiImIX10oyqH/0t5Wq59RJbSlNRET0lFZ6Z2VekYiIGFArzVl7AP+V584nckH7ihUREb2gleasa4EnqAZe3LKdYyMiYhRpJYlMsD297SWJiIie08oovv8m6bfaXpKIiOg5rTyJHAF8sHy5voVq4EPbfkNbSxYRESNeK0nk2LaXIiIielIrXXwf6kRBIka7SbOu63YRInZYK+9EIiIiBpQkEhERjSWJREREY0kiERHRWNeSiKRVkpZLWiZpaYntI2mRpPvLz71LXJK+KGmFpDvrIwtLmlGOv1/SjG7VJyJiNOr2k8g7bE+13Tfx1Sxgse0pwOKyDVU34yllmQnMgSrpAOcBhwGHAuf1JZ6IiGi/bieR/k4A+uZ0nw+cWItf5srNwF6SxgPHAItsb7T9GLAIyBAtEREd0s3JpQx8X5KBr9ieC4yzvbbsfwQYV9b3Bx6unbu6xAaLP4ukmVRPMEycOHE46xARQ9jety+rZmeS1F7XzSRyhO01kl4OLJL0k/pO2y4JZqeVBDUXYNq0acNyzYiI6GJzlu015ed64BqqdxrrSjMV5ef6cvga4IDa6RNKbLB4RER0QFeeRCS9CNjN9uayfjRwAbAAmAHMLj+vLacsAM6WdCXVS/QnbK+VdD3wl7WX6UcD53awKhHPkuabGG261Zw1DrhGUl8Zvm77e5KWAFdJOh14iGfmcl8IHAesAJ4CTgOwvVHSXwBLynEX2N7YuWpERIxuXUkitlcCbxwg/ihw1ABxA2cNcq15wLzhLmNEtCYDR45uI62Lb0RE9JAkkYiIaCxJJCIiGuvmdyIRo07eH8SuJk8iERHRWJJIREQ0liQSERGNJYlERERjSSIREdFYkkhERDSWJBIREY0liURERGNJIhER0ViSSERENJYkEhERjSWJREREYx1PIpIOkHSDpHsk3S3pnBI/X9IaScvKclztnHMlrZB0n6RjavHpJbZC0qxO1yUiYrTrxii+W4GP275d0p7AbZIWlX2ft/3X9YMlHQScDLwO2A/4gaRXl91fAt4FrAaWSFpg+56O1CIiIjqfRGyvBdaW9c2S7gX2H+KUE4ArbW8BHpS0Aji07FtRptpF0pXl2CSRiIgO6eo7EUmTgDcBt5TQ2ZLulDRP0t4ltj/wcO201SU2WHyg+8yUtFTS0g0bNgxnFSIiRrWuJRFJLwauBj5mexMwB3glMJXqSeVvhutetufanmZ72tixY4frshERo15XZjaU9DyqBHK57W8B2F5X2/9V4Dtlcw1wQO30CSXGEPGIiOiAbvTOEnAJcK/ti2vx8bXD3gPcVdYXACdL2kPSZGAKcCuwBJgiabKk51O9fF/QiTpERESlG08ibwU+ACyXtKzEPgWcImkqYGAV8McAtu+WdBXVC/OtwFm2twFIOhu4HhgDzLN9d+eqERER3eid9SNAA+xaOMQ5FwIXDhBfONR5ERHRXvliPSIiGksSiYiIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjGkkQiIqKxJJGIiGisK2NnRUQATJp13ZD7V80+vkMliaaSRCJ2wPb+0osYbZJEIvpJohg5hvqzyFPKyJB3IhER0ViSSERENJYkEhERjSWJREREY0kiERHRWJJIREQ01vNJRNJ0SfdJWiFpVrfLExExmvT0dyKSxgBfAt4FrAaWSFpg+57ulixGsnwHsmvI1+4jQ08nEeBQYIXtlQCSrgROAJJERrkkikiS6YxeTyL7Aw/XtlcDh/U/SNJMYGbZfFLSfS1ce1/gZztdwpFhV6oLpD4jWc/URRe1dFjP1KcFO1uXVwwU7PUk0hLbc4G5O3KOpKW2p7WpSB21K9UFUp+RbFeqC+xa9WlXXXr9xfoa4IDa9oQSi4iIDuj1JLIEmCJpsqTnAycDC7pcpoiIUaOnm7Nsb5V0NnA9MAaYZ/vuYbr8DjV/jXC7Ul0g9RnJdqW6wK5Vn7bURbbbcd2IiBgFer05KyIiuihJJCIiGksS6afXh1GRNE/Sekl31WL7SFok6f7yc+9ulrFVkg6QdIOkeyTdLemcEu/V+rxA0q2S/r3U53+W+GRJt5TfuW+UTiI9QdIYSXdI+k7Z7uW6rJK0XNIySUtLrCd/1wAk7SXpm5J+IuleSW9pR32SRGpqw6gcCxwEnCLpoO6WaoddCkzvF5sFLLY9BVhctnvBVuDjtg8CDgfOKn8evVqfLcA7bb8RmApMl3Q4cBHweduvAh4DTu9eEXfYOcC9te1ergvAO2xPrX1P0au/awBfAL5n+7XAG6n+nIa/PrazlAV4C3B9bftc4Nxul6tBPSYBd9W27wPGl/XxwH3dLmPDel1LNU5az9cH+A3gdqoRFn4G7F7iz/odHMkL1XdZi4F3At8B1Kt1KeVdBezbL9aTv2vAS4EHKZ2n2lmfPIk820DDqOzfpbIMp3G215b1R4Bx3SxME5ImAW8CbqGH61Oaf5YB64FFwAPA47a3lkN66Xfub4FPAk+X7ZfRu3UBMPB9SbeVoZKgd3/XJgMbgH8qzY3/KOlFtKE+SSKjjKt/gvRUv25JLwauBj5me1N9X6/Vx/Y221Op/hV/KPDa7paoGUnvBtbbvq3bZRlGR9g+mKo5+yxJb6/v7LHftd2Bg4E5tt8E/Jx+TVfDVZ8kkWfbVYdRWSdpPED5ub7L5WmZpOdRJZDLbX+rhHu2Pn1sPw7cQNXks5ekvg9/e+V37q3A70paBVxJ1aT1BXqzLgDYXlN+rgeuoUryvfq7thpYbfuWsv1NqqQy7PVJEnm2XXUYlQXAjLI+g+rdwognScAlwL22L67t6tX6jJW0V1l/IdX7nXupksl7y2E9UR/b59qeYHsS1f8n/2L7D+nBugBIepGkPfvWgaOBu+jR3zXbjwAPS3pNCR1FNUXGsNcnX6z3I+k4qrbevmFULuxuiXaMpCuAI6mGfV4HnAd8G7gKmAg8BJxke2OXitgySUcA/wos55l2909RvRfpxfq8AZhP9bu1G3CV7QskHUj1r/l9gDuA99ve0r2S7hhJRwJ/ZvvdvVqXUu5ryubuwNdtXyjpZfTg7xqApKnAPwLPB1YCp1F+7xjG+iSJREREY2nOioiIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjGkkRilybpyTZcc2rpCt63fb6kP9uJ6/1+GWX1huEpYeNyrJK0bzfLEL0nSSRix00FjtveQTvgdOAM2+8YxmtGdESSSIwakj4haYmkO2tzeUwqTwFfLXN8fL98TY6kN5djl0n6nKS7ykgGFwDvK/H3lcsfJOlGSSslfXSQ+59S5qu4S9JFJfYZ4AjgEkmf63f8eEk3lfvcJeltJT5H0lLV5iQp8VWS/qpvPgxJB0u6XtIDks4sxxxZrnmdqnlzvizpOX8PSHq/qrlPlkn6Shk4coykS0tZlkv6bzv5RxK7gm4PWZwlSzsX4Mny82hgLtVw5btRDV3+dqph87cCU8txV1F9ZQ3VsBdvKeuzKcPrAx8E/r52j/OBfwP2oBop4FHgef3KsR/wH8BYqi+i/wU4sey7EZg2QNk/Dvx5WR8D7FnW96nFbgTeULZXAX9S1j8P3AnsWe65rsSPBP4TOLCcvwh4b+38fYHfBP5PXx2AfwBOBQ4BFtXKt1e3/3yzdH/Jk0iMFkeX5Q6qeTxeC0wp+x60vays3wZMKmNc7Wn7xyX+9e1c/zrbW2z/jGpQu/5DbL8ZuNH2BldDpV9OlcSGsgQ4TdL5wG/Z3lziJ0m6vdTldVQTqPXpG+ttOXCL7c22NwBb+sbtAm61vdL2NuAKqiehuqOoEsaSMmz9UVRJZyVwoKS/kzQd2ESMertv/5CIXYKAv7L9lWcFq3lK6mM7bQNe2OD6/a+x0/9v2b6pDEd+PHCppIupxhL7M+DNth+TdCnwggHK8XS/Mj1dK1P/sY76bwuYb/vc/mWS9EbgGOBM4CTgQztar9i15EkkRovrgQ+VuUmQtL+klw92sKuh2jdLOqyETq7t3kzVTLQjbgX+i6R9VU3DfArww6FOkPQKqmaor1INpHcw8BKquSGekDSOau6LHXVoGal6N+B9wI/67V8MvLfvv4+qeblfUXpu7Wb7auDTpTwxyuVJJEYF29+X9JvAj6sR5nkSeD/VU8NgTge+Kulpqr/wnyjxG4BZpannr1q8/1pJs8q5omr+2t4w3EcCn5D0q1LeU20/KOkO4CdUs3D+31bu388S4O+BV5XyXFPfafseSZ+mmuVvN+BXwFnAL6hmyuv7x+dznlRi9MkovhGDkPRi20+W9VlUc1Of0+Vi7ZT6sO1dLkrsIvIkEjG44yWdS/X/yUNUvbIioiZPIhER0VherEdERGNJIhER0ViSSERENJYkEhERjSWJREREY/8fU5BFBanEMtgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('headlines')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "electoral-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 40 #그래프를 보고 적당히 변경\n",
    "headlines_max_len = 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "velvet-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s.split()) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "worldwide-netherlands",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 40 이하인 샘플의 비율: 0.9238714924766165\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.2755693371289142\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "weird-execution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 25130\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "golden-agent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>odisha cm patnaik controls mining mafia union ...</td>\n",
       "      <td>union minister dharmendra pradhan wednesday cl...</td>\n",
       "      <td>sostoken odisha cm patnaik controls mining maf...</td>\n",
       "      <td>odisha cm patnaik controls mining mafia union ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>isro unveils bengaluru centre for manned space...</td>\n",
       "      <td>indian space research organisation wednesday u...</td>\n",
       "      <td>sostoken isro unveils bengaluru centre for man...</td>\n",
       "      <td>isro unveils bengaluru centre for manned space...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>killed injured in saudi arabia floods</td>\n",
       "      <td>least people killed others injured saudi arabi...</td>\n",
       "      <td>sostoken killed injured in saudi arabia floods</td>\n",
       "      <td>killed injured in saudi arabia floods eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>seat cushions from missing plane carrying foot...</td>\n",
       "      <td>investigators searching lost plane carrying ar...</td>\n",
       "      <td>sostoken seat cushions from missing plane carr...</td>\n",
       "      <td>seat cushions from missing plane carrying foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>agustawestland scam accused rajiv saxena extra...</td>\n",
       "      <td>agustawestland chopper scam co accused rajiv s...</td>\n",
       "      <td>sostoken agustawestland scam accused rajiv sax...</td>\n",
       "      <td>agustawestland scam accused rajiv saxena extra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headlines  \\\n",
       "19  odisha cm patnaik controls mining mafia union ...   \n",
       "21  isro unveils bengaluru centre for manned space...   \n",
       "22              killed injured in saudi arabia floods   \n",
       "29  seat cushions from missing plane carrying foot...   \n",
       "36  agustawestland scam accused rajiv saxena extra...   \n",
       "\n",
       "                                                 text  \\\n",
       "19  union minister dharmendra pradhan wednesday cl...   \n",
       "21  indian space research organisation wednesday u...   \n",
       "22  least people killed others injured saudi arabi...   \n",
       "29  investigators searching lost plane carrying ar...   \n",
       "36  agustawestland chopper scam co accused rajiv s...   \n",
       "\n",
       "                                        decoder_input  \\\n",
       "19  sostoken odisha cm patnaik controls mining maf...   \n",
       "21  sostoken isro unveils bengaluru centre for man...   \n",
       "22     sostoken killed injured in saudi arabia floods   \n",
       "29  sostoken seat cushions from missing plane carr...   \n",
       "36  sostoken agustawestland scam accused rajiv sax...   \n",
       "\n",
       "                                       decoder_target  \n",
       "19  odisha cm patnaik controls mining mafia union ...  \n",
       "21  isro unveils bengaluru centre for manned space...  \n",
       "22     killed injured in saudi arabia floods eostoken  \n",
       "29  seat cushions from missing plane carrying foot...  \n",
       "36  agustawestland scam accused rajiv saxena extra...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "consecutive-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "constitutional-participant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25130"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "historical-glucose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18040 20692  7369 ... 19820 14398  2925]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "confidential-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "confidential-philosophy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 5026\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "vulnerable-preparation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 20104\n",
      "훈련 레이블의 개수 : 20104\n",
      "테스트 데이터의 개수 : 5026\n",
      "테스트 레이블의 개수 : 5026\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-passion",
   "metadata": {},
   "source": [
    "### 단어 집합(vocabulary) 만들기 및 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "right-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "muslim-january",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 40239\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 29199\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11040\n",
      "단어 집합에서 희귀 단어의 비율: 72.56393051517185\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 8.66388970507746\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "together-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 11800 # 이데이터셋 기준 8천은 적다\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 11800으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "extreme-wireless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 27, 62, 5822, 18, 1857, 1699, 5593, 20, 1302, 23, 5594, 2914, 2521, 1, 8726, 1258, 790, 10103, 6921, 1577, 1128, 1034, 442, 3091, 3386, 5048, 6922], [3036, 666, 1097, 6319, 16, 47, 700, 714, 2980, 122, 285, 3971, 704, 8727, 112, 6319, 7707, 5410, 3812, 722, 1, 563, 231, 2727, 32, 530, 809, 5225, 455], [1886, 14, 693, 68, 1987, 5226, 552, 931, 61, 693, 10104, 660, 536, 49, 217, 1988, 10105, 317, 86, 152, 107, 3227, 755, 292, 931, 3, 417, 20, 1302, 285, 1755, 1558, 4749, 285]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "guided-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "guided-array",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 18098\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 13688\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 4410\n",
      "단어 집합에서 희귀 단어의 비율: 75.6326665929937\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 14.628542990405426\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "olive-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 42, 61, 74, 3, 3476], [1, 2387, 935, 2075, 409, 304, 4], [1, 20, 455, 197, 1918, 716, 105], [1, 146, 78, 17, 18, 272, 1919, 3894], [1, 350, 509, 235, 17, 3127, 3477]]\n",
      "target\n",
      "decoder  [[42, 61, 74, 3, 3476, 2], [2387, 935, 2075, 409, 304, 4, 2], [20, 455, 197, 1918, 716, 105, 2], [146, 78, 17, 18, 272, 1919, 3894, 2], [350, 509, 235, 17, 3127, 3477, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 4410 #위를 참조하여 줄임\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "attached-serbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 20103\n",
      "훈련 레이블의 개수 : 20103\n",
      "테스트 데이터의 개수 : 5026\n",
      "테스트 레이블의 개수 : 5026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "determined-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='pre', truncating='pre')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='pre', truncating='pre')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='pre', truncating='pre')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='pre', truncating='pre')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='pre', truncating='pre')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='pre', truncating='pre')\n",
    "#lstm에는 pre가 좋다고 들어서 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-elephant",
   "metadata": {},
   "source": [
    "### 모델설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "english-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "considered-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dress-variety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 128)      1510400     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 40, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 40, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    564480      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 40, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 4410)   1133370     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,047,354\n",
      "Trainable params: 5,047,354\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-overhead",
   "metadata": {},
   "source": [
    "### 어텐션 메커니즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "insured-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "competent-luxembourg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 128)      1510400     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 40, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 40, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    564480      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 40, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 4410)   2262330     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,307,642\n",
      "Trainable params: 6,307,642\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "optimum-singapore",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 245s 9s/step - loss: 6.0705 - val_loss: 5.6422\n",
      "Epoch 2/50\n",
      "15/27 [===============>..............] - ETA: 1:38 - loss: 5.7571"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-e2fda1314d35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           batch_size=768, callbacks=[es], epochs=50)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=768, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-baseline",
   "metadata": {},
   "source": [
    "단어수좀 늘렸더니 이꼴이네요 제가 클라우드 주소가 잘못 뽑힌건가요 15시간? 걸리네요 안타깝지만 시험 여러번 못하고 마칠것 같습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-china",
   "metadata": {},
   "source": [
    "### 인퍼런스 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-terrace",
   "metadata": {},
   "source": [
    "### 모델 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(77, 87):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-closure",
   "metadata": {},
   "source": [
    "많이 해매는걸 볼수있다    \n",
    "임의대로 개량하다가 예측 결과가 한가지로만 나온다 내가 뭘고쳤지 ㅠ 앞으론 그 탭을 복사해놓고 주석화해놓고 고쳐야겠다\n",
    "불용어를 제거한탓에 문장이 자연스럽지 않다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-potato",
   "metadata": {},
   "source": [
    "추출적 요약 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip list | grep summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text\n",
    "#예제 샘플\n",
    "#print(text[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.values.tolist()[50][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(text.values.tolist()[21584][1], words=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2text(encoder_input_test[2500]) #인덱스 값이 변한걸 찾아 해맸지만 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    print(\"원문 :\", text.values.tolist()[i][1],\"\\n\")\n",
    "    print(\"추출 요약 :\", summarize(text.values.tolist()[i][1], words=20))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-divide",
   "metadata": {},
   "source": [
    "- 확실히 추출적 요약이 원단어를 그대로 써서 완성도가 높다 하지만 대부분 핵심적인 문장을 선택해서 그대로 받는 경우가 많고 짧게 줄이려고하면 아예 결과가 안나오는 둥 문제점은 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-sponsorship",
   "metadata": {},
   "source": [
    "|No.|평가문항|상세기준|\n",
    "|-|:-|:-|\n",
    "|1.| Abstractive 모델 구성을 위한 텍스트 전처리 단계가 체계적으로 진행되었다.|분석단계, 정제단계, 정규화와 불용어 제거, 데이터셋 분리, 인코딩 과정이 빠짐없이 체계적으로 진행되었다.\n",
    "|2.| 텍스트 요약모델이 성공적으로 학습되었음을 확인하였다.|모델학습이 안정적으로 수렴되었음을 그래프를 통해 확인하였으며, 실제 요약문과 유사한 요약문장을 얻을 수 있었다.\n",
    "|3.| Extractive 요약을 시도해 보고 Abstractive 요약 결과과 함께 비교해 보았다.|두 요약 결과를 문법완성도 측면과 핵심단어 포함 측면으로 나누어 비교분석 결과를 제시하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-senate",
   "metadata": {},
   "source": [
    "# 회고\n",
    "- 이번건 별로 터지는 곳이 없어서 안심을 하고 추출결과와 추상적 요약결과를 비교하겠다고    \n",
    "열심히 변환된 인덱스 값을 찾아 해매느라 시간은 시간대로 쓰고 결과도 안나왔습니다 ㅠ\n",
    "- 터지면 터지는거 고치다가 배우는 것도 많던데 슬프네요\n",
    "- 이거저거 시험하다가 추측요약 내용이 망가졌다 돌리는데 오래걸리는데 ㅠ 어디서 망가진걸까"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
